================================================================================
DIGICOW HACKATHON — SOLUTION EVOLUTION & WHAT WORKED
================================================================================
Team: Princess-B-Kwaniya
Competition: Zindi DigiCow — Predicting Dairy Technology Adoption
Metric: Per-target 0.75*LogLoss + 0.25*(1-AUC), summed across 3 targets
        HIGHER leaderboard score = BETTER

================================================================================
FINAL BEST SCORE: 0.72828 (sub_DUAL_f1_g3_w3.csv)
================================================================================

APPROACH: Bayesian hierarchical group smoothing with DUAL column strategy
          + zero-adoption group post-processing rules

================================================================================
SCORE PROGRESSION
================================================================================

Version  | LB Score | Strategy                              | Status
---------|----------|---------------------------------------|--------
V3       | 0.722    | Bayesian hierarchical groups, s=3     | Baseline
V7 DUAL  | 0.723    | Separate AUC/LL columns              | Improvement
V9       | 0.7247   | topic=0 fix (99 rows → 0.001)        | Improvement
V12/DUAL | 0.72828  | + group/subcounty zero rules          | BEST ★

FAILED ATTEMPTS (all scored WORSE):
V8       | 0.695    | Fine-grained hierarchy for LL column  | Overfitted
V10 S1   | 0.720    | LightGBM predictions in LL column     | Overfitted
V10 FIXA | <0.7247  | Month/seasonal AUC hierarchy          | Hurt ranking
V11 FIX1 | 0.7241   | sqrt(n) smoothing for AUC             | Marginally worse
V11 FIX3 | 0.7246   | 70%V9 + 30%sqrt blend                 | Marginally worse
SUPER_A  | <0.7247  | LGBM ensemble for AUC column          | LGBM rankings worse
DUAL #3  | 0.7097   | Added ward_topic + farmer zero rules  | Overfit on rules

================================================================================
WHAT WORKED (and why)
================================================================================

1. BAYESIAN HIERARCHICAL GROUP SMOOTHING (V3)
   ─────────────────────────────────────────
   Formula: pred = (count * group_mean + s * global_mean) / (count + s)
   
   Hierarchy for LogLoss (V3, s=3):
     trainer_ward_topic → trainer_ward → trainer_county_topic →
     ward_topic → county_topic → trainer → ward → county
   
   Hierarchy for AUC (V7 fine, s=3):
     ward_group → group_name → ward_topic → county_topic →
     ward → county → trainer
   
   WHY: The data is fundamentally about GROUP behavior. Farmers in the
   same ward/group/trainer tend to adopt similarly. Bayesian smoothing
   prevents overfitting on small groups while capturing the signal.

2. DUAL COLUMN STRATEGY (V7)
   ──────────────────────────
   Key insight: Zindi evaluates AUC and LogLoss from SEPARATE columns.
   AUC only cares about RANKING → use fine-grained groups (ward_group first)
   LogLoss cares about CALIBRATION → use trainer-first hierarchy
   
   V7 used different optimal hierarchies per column type:
   - AUC columns: ward_group → group_name → ... (ranking-optimized)
   - LL columns: trainer_ward_topic → trainer_ward → ... (calibration-optimized)
   
   WHY: A single set of predictions can't optimize both metrics.

3. TOPIC=0 FIX (V9)
   ─────────────────
   Discovery: 838 train rows with has_topic_trained_on=0 have ZERO adoption
   across ALL 3 targets (0/838 = 0.0%). This is deterministic.
   99 test rows have has_topic_trained_on=0.
   Fix: Force those 99 rows to 0.001 in both AUC and LL columns.
   Impact: V7 (0.723) → V9 (0.7247)
   
   WHY: These farmers were trained on topics they weren't interested in,
   so they never adopted. The signal is absolute — zero exceptions in
   838 training observations.

4. ZERO-GROUP RULES (V12/DUAL — BEST SCORE)
   ──────────────────────────────────────────
   Extension of the topic=0 concept:
   - Find group_topic combos with 0 adoptions AND 30+ training samples
   - Find subcounty_topic combos with same pattern
   - Force matching test rows to 0.001 in both columns
   
   group_topic: group_name + has_topic_trained_on (42 rules, 2425 test rows)
   subcounty_topic: subcounty + has_topic_trained_on (33 rules, 1848 test rows)
   
   700-933 rows changed per target (LL column adjustments)
   Impact: V9 (0.7247) → 0.72828
   
   WHY: Same principle as topic=0. Entire groups/subcounties where NO ONE
   adopted technology with 30+ historical examples → safe to set near-zero.

================================================================================
WHAT FAILED (critical lessons)
================================================================================

1. LGBM / ML MODELS FOR PREDICTIONS
   Teammate's LightGBM (V4.1f) had strong CV AUC (~0.97) but REPLACING
   V9's AUC column with LGBM predictions scored WORSE on LB. The Bayesian
   hierarchy captures group-level signals better than individual-level ML.
   
   LGBM for LL column was even worse (V10 S1 = 0.720).
   Rank correlation between LGBM and V9 was only 0.66-0.69 — they rank
   test rows very differently.

2. CHANGING SMOOTHING / HIERARCHY
   Every attempt to optimize smoothing (sqrt(n), per-level tuning) or
   hierarchy order HURT on LB despite improving CV. The competition's
   train/test split has distributional differences that CV can't capture.

3. AGGRESSIVE RULES
   ward_topic zero rules + farmer-level zero rules DESTROYED the score
   (0.7097). Only group_topic and subcounty_topic zero rules are reliable.
   Ward-level and individual-level rules overfit.

4. BLENDING WITH LGBM
   Even 5% LGBM blend, 30% blend, rank-averaging — all hurt.
   The hierarchical approach IS the right model for this data.

5. CALIBRATION (Isotonic, Platt)
   Marginal at best, often harmful. The Bayesian smoothing already
   produces well-calibrated probabilities.

================================================================================
KEY FILES
================================================================================

WINNING SUBMISSION: sub_DUAL_f1_g3_w3.csv (LB 0.72828)
  Generated by: DUAL_FINAL.py
  Base: V9 (sub_V9_A_v7_topicfix.csv, LB 0.7247)
  + group_topic zero rules (30+ training samples, 0% adoption)
  + subcounty_topic zero rules (30+ training samples, 0% adoption)

PIPELINE ANCESTRY:
  GROUPS_V3.py → exhaustive CV search for best hierarchy per target
  GROUPS_V3_FAST.py → fast version with fixed hierarchy
  V7_SAFE.py → DUAL column strategy (separate AUC/LL hierarchies)
  V9_TOPICFIX.py → topic=0 post-processing fix
  DUAL_FINAL.py → zero-group rules + teammate's LGBM (rules-only won)

TEAMMATE'S MODEL:
  CompetitiveSolution.ipynb — LightGBM + LogisticRegression ensemble
  Features: V2.5d base + OOF target encoding + Optuna tuning
  Used for confidence analysis but NOT in final predictions

================================================================================
FINAL ARCHITECTURE
================================================================================

  Train.csv ──┐
              ├──→ Bayesian Hierarchy (s=3) ──┐
  Test.csv  ──┘                               │
                                              ├──→ DUAL Strategy ──→ Post-Processing ──→ Submission
                                              │    (separate AUC     (topic=0 fix +
                                              │     and LL columns)   zero-group rules)
              V7_FINE hierarchy:               │
              ward_group → group_name →        │
              ward_topic → county_topic →      │
              ward → county → trainer          │
                    (for AUC columns)          │
                                              │
              V3 hierarchy:                    │
              trainer_ward_topic →             │
              trainer_ward → trainer_county_topic →
              ward_topic → county_topic →
              trainer → ward → county
                    (for LL columns)

================================================================================
